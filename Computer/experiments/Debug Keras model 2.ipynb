{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "collapsed": false
   },
>>>>>>> 5908e72ecd3f221408ece6f7db2483c45870a287
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import keras\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Flatten, Dense, Lambda, Cropping1D, Cropping2D\n",
    "from keras.layers import Conv2D, Dropout\n",
    "from keras.layers.pooling import MaxPooling2D\n",
    "from keras.optimizers import Adam\n",
    "import numpy as np\n",
    "import csv\n",
    "from sklearn.utils import shuffle\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from image_pipeline import Operation, Color, Sobel, Magnitude, Direction, \\\n",
    "  Threshold, Combinator, FindLinesSlidingWindows, Annotate, ImagePipeline\n",
    "import pickle\n",
    "\n",
    "MODEL_H5 = '/home/sku/model.h5'\n",
    "\n",
    "TARGET_WIDTH = 320\n",
    "TARGET_HEIGHT = 240\n",
    "TARGET_CROP = ((60, 20), (0, 0))\n",
    "\n",
    "# Look into Arduino code's car.h for SteerFeedMin_ and SteerFeedMax_\n",
    "STEER_MIN = 30\n",
    "STEER_MAX = 993\n",
    "\n",
    "STEER_FIELD_ID = 1\n",
    "SPEED_FIELD_ID = 2\n",
    "\n",
    "IMG_DIR = \"C:\\\\Users\\\\teguh\\\\Dropbox\\\\Projects\\\\Robotics\\\\Self-Driving-RC-Data\\\\recorded-2017-06-01.1\\\\recorded\"\n",
    "DATA_FILE = \"C:\\\\Users\\\\teguh\\\\Dropbox\\\\Projects\\\\Robotics\\\\Self-Driving-RC-Data\\\\recorded-2017-06-01.1\\\\recorded.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debugging Keras Module\n",
    "\n",
    "First, let's see how the image looks like before it was passed to learner model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
<<<<<<< HEAD
   "metadata": {},
=======
   "metadata": {
    "collapsed": false
   },
>>>>>>> 5908e72ecd3f221408ece6f7db2483c45870a287
   "outputs": [],
   "source": [
    "model = load_model(MODEL_H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "import h5py\n",
    "\n",
    "def print_structure(weight_file_path):\n",
    "    \"\"\"\n",
    "    Prints out the structure of HDF5 file.\n",
    "\n",
    "    Args:\n",
    "      weight_file_path (str) : Path to the file to analyze\n",
    "    \"\"\"\n",
    "    f = h5py.File(weight_file_path)\n",
    "    try:\n",
    "        if len(f.attrs.items()):\n",
    "            print(\"{} contains: \".format(weight_file_path))\n",
    "            print(\"Root attributes:\")\n",
    "        for key, value in f.attrs.items():\n",
    "            print(\"  {}: {}\".format(key, value))\n",
    "\n",
    "        if len(f.items())==0:\n",
    "            return \n",
    "\n",
    "        for layer, g in f.items():\n",
    "            print(\"  {}\".format(layer))\n",
    "            print(\"    Attributes:\")\n",
    "            for key, value in g.attrs.items():\n",
    "                print(\"      {}: {}\".format(key, value))\n",
    "\n",
    "            print(\"    Dataset:\")\n",
    "            for p_name in g.keys():\n",
    "                param = g[p_name]\n",
    "                print(\"      {}: {}\".format(p_name, param.shape))\n",
    "    finally:\n",
    "        f.close()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
   "metadata": {},
=======
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
>>>>>>> 5908e72ecd3f221408ece6f7db2483c45870a287
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'lambda_1', 'trainable': True, 'batch_input_shape': (None, 240, 320, 1), 'dtype': 'float32', 'function': ('ã\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x01\\x00\\x00\\x00\\x02\\x00\\x00\\x00C\\x00\\x00\\x00s\\x08\\x00\\x00\\x00|\\x00d\\x01\\x1b\\x00S\\x00)\\x02Ng\\x00\\x00\\x00\\x00\\x00ào@©\\x00)\\x01Ú\\x01xr\\x01\\x00\\x00\\x00r\\x01\\x00\\x00\\x00ú3/home/jay/Self-Driving-RC/Computer/learner/learn.pyÚ\\x08<lambda>\\x9c\\x00\\x00\\x00ó\\x00\\x00\\x00\\x00', None, None), 'function_type': 'lambda', 'output_shape': None, 'output_shape_type': 'raw', 'arguments': {}}\n",
      "{'name': 'cropping2d_1', 'trainable': True, 'cropping': ((60, 20), (0, 0)), 'data_format': 'channels_last'}\n",
      "{'name': 'conv2d_1', 'trainable': True, 'filters': 24, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(5, 5, 1, 24)\n",
      "Second:\n",
      "[-0.0501535  -0.04859334 -0.03379487 -0.006406   -0.00755421 -0.00681409\n",
      " -0.00570126 -0.02348518 -0.0070845  -0.03846463  0.00515019  0.00155862\n",
      " -0.00804036  0.00171206 -0.05359589 -0.00681117 -0.00781038 -0.00605484\n",
      " -0.04888411 -0.00652615  0.00362918 -0.05123394 -0.04731317 -0.04603482]\n",
      "{'name': 'conv2d_2', 'trainable': True, 'filters': 36, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(5, 5, 24, 36)\n",
      "Second:\n",
      "[ -5.29074073e-02  -3.74316610e-02   1.39460876e-03  -3.07546053e-02\n",
      "  -1.58342700e-02  -2.04240717e-02   8.15994292e-03  -8.40748078e-04\n",
      "  -1.07680783e-02  -1.22574558e-02  -1.69302046e-04   1.02880402e-02\n",
      "  -1.09250382e-01  -3.52530368e-02  -4.55655232e-02  -2.84889005e-02\n",
      "   3.94083699e-03  -2.20373627e-02  -5.17499745e-02  -5.43738948e-03\n",
      "  -2.52098795e-02  -1.35160470e-02  -1.92488417e-01  -3.06284167e-02\n",
      "  -4.13885601e-02  -9.72926337e-03   5.55795431e-03  -5.42180464e-02\n",
      "  -1.31594390e-02  -7.86406919e-03  -4.39089816e-03  -3.55879590e-02\n",
      "  -3.62455100e-02  -2.89275870e-03  -1.02606183e-02  -6.12082379e-03]\n",
      "{'name': 'conv2d_3', 'trainable': True, 'filters': 48, 'kernel_size': (5, 5), 'strides': (2, 2), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(5, 5, 36, 48)\n",
      "Second:\n",
      "[-0.07594334 -0.01488655 -0.03838882 -0.02995209 -0.09618703 -0.07131954\n",
      " -0.08586993 -0.02567879 -0.03264178 -0.02182197 -0.0365102  -0.11242855\n",
      " -0.04171317 -0.02267807 -0.00672883 -0.03375321 -0.03701716 -0.00905107\n",
      " -0.03665973 -0.03478604 -0.05374419 -0.09905836 -0.03729417 -0.01904579\n",
      " -0.04842818 -0.02972382 -0.03850301 -0.00876625 -0.04291487 -0.03298013\n",
      " -0.04845853 -0.06907164 -0.11335865 -0.02451015 -0.0442057  -0.00566948\n",
      "  0.00108752 -0.04256332  0.00882601 -0.03808734 -0.08496872 -0.08444232\n",
      " -0.17907816 -0.1007426  -0.03095728 -0.04011739 -0.03012686 -0.04117815]\n",
      "{'name': 'conv2d_4', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(3, 3, 48, 64)\n",
      "Second:\n",
      "[-0.1081758  -0.04512652 -0.00892504 -0.06592407 -0.04528275 -0.21341103\n",
      " -0.01020313 -0.06327112  0.11540874 -0.11457592 -0.0714687  -0.07923511\n",
      " -0.2328642  -0.05336449 -0.04511944 -0.0236694  -0.06281472 -0.09039396\n",
      " -0.01783056 -0.06410041 -0.30123511 -0.5899933  -0.00560428 -0.10499471\n",
      " -0.07006288 -0.01631204 -0.06846411 -0.05398695 -0.05566147 -0.0395748\n",
      " -0.03585021 -0.04183326 -0.05469115 -0.08098889 -0.41292718 -0.03666264\n",
      " -0.03825979 -0.24605536 -0.50813758 -0.09491605 -0.09093668 -0.03977681\n",
      " -0.05077571 -0.01998173 -0.05522815 -0.07112438 -0.12703027 -0.04031245\n",
      " -0.05889097 -0.01062844 -0.04833868 -0.00978349 -0.03888611 -0.04045095\n",
      " -0.06772643 -0.12871578 -0.04711531 -0.0172707  -0.01678114 -0.03635535\n",
      " -0.08359935 -0.08591709 -0.33000395 -0.08623508]\n",
      "{'name': 'conv2d_5', 'trainable': True, 'filters': 64, 'kernel_size': (3, 3), 'strides': (1, 1), 'padding': 'valid', 'data_format': 'channels_last', 'dilation_rate': (1, 1), 'activation': 'relu', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(3, 3, 64, 64)\n",
      "Second:\n",
      "[ 0.01573061  0.0021914  -0.3202925   0.04259459 -0.04170884  0.0545296\n",
      "  0.08043268 -0.01186186 -0.11766745 -0.05035855  0.32106346 -0.04208142\n",
      " -0.03219021  0.00788019  0.01572369 -0.29452926  0.05138735 -0.05958945\n",
      " -0.02398386 -0.19807912  0.01189586 -0.06988283  0.09895811  0.02560423\n",
      " -0.10518995  0.01204144  0.13298479  0.03050157 -0.07670456 -0.11087648\n",
      " -0.00306392 -0.0210502   0.02559043  0.1113825   0.06178537 -0.05686275\n",
      " -0.05275802 -0.12061704  0.15417853  0.09489574 -0.00808811  0.08156632\n",
      " -0.07848152 -0.14384763 -0.0473711  -0.04102664 -0.127933    0.03417051\n",
      " -0.00587604 -0.25047204 -0.01099228  0.02051719  0.07456971  0.05279855\n",
      " -0.11242173 -0.01680725 -0.03902993 -0.04454133 -0.04966735 -0.07275338\n",
      " -0.03317195 -0.08914942 -0.05480562 -0.03729835]\n",
      "{'name': 'flatten_1', 'trainable': True}\n",
      "{'name': 'dense_1', 'trainable': True, 'units': 100, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(27456, 100)\n",
      "Second:\n",
      "[ 0.07999464 -0.19490403  0.31829762  0.47854084 -0.21436502  0.63030303\n",
      " -0.22591795  0.26000446 -0.25772053  0.62352449 -0.5565933  -0.07026751\n",
      "  0.22734688  0.33958113 -0.56227434  0.46840772 -0.19340503  0.26002771\n",
      " -0.27669522  0.40797535 -0.61332369 -0.43414456  0.18055105  0.29982349\n",
      "  0.17897969  0.13987865  0.54742247  0.05562076  0.61987823  0.53624004\n",
      " -0.59423888 -0.34624353 -0.26470131  0.21819107 -0.165071    0.15286323\n",
      "  0.14191782 -0.3765178  -0.52905738  0.55505949  0.19450845  0.63238066\n",
      "  0.19426148 -0.34493586 -0.19924554 -0.4646036  -0.33838287 -0.40155566\n",
      "  0.32530597 -0.57920909 -0.18851519  0.55162549 -0.22725523 -0.5696649\n",
      " -0.60255432  0.32791665 -0.52556705  0.08752598 -0.51342702  0.15688865\n",
      "  0.3872242   0.40521622 -0.22314714  0.40689039 -0.3074275  -0.23405021\n",
      "  0.28973481 -0.62928504 -0.30134985  0.057291   -0.61025852 -0.23154856\n",
      " -0.23353019 -0.60784942 -0.2013928  -0.39129427 -0.23063804  0.61926419\n",
      " -0.2920942  -0.27983803 -0.22034971  0.35573867 -0.23581615 -0.22682117\n",
      "  0.26131755  0.3098858   0.54962742  0.22889537  0.28117758  0.20759709\n",
      " -0.27538511  0.46620637 -0.55197841  0.28543273  0.53611672  0.28730759\n",
      " -0.31350639  0.36090118 -0.45791683 -0.21936689]\n",
      "{'name': 'dense_2', 'trainable': True, 'units': 50, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(100, 50)\n",
      "Second:\n",
      "[ 0.08264162 -0.45002377  0.35054043 -0.63758749  0.09531074  0.58972979\n",
      "  0.64008224 -0.70936733 -0.59317547 -0.33896115  0.68965197 -0.57886803\n",
      " -0.04034556  0.63863862  0.03330076 -0.71337163 -0.65064895 -0.42760703\n",
      " -0.52895343  0.61301708  0.36531883 -0.68720323 -0.09755334 -0.19327039\n",
      " -0.70944422  0.08399623 -0.27844638 -0.19151722 -0.59824777  0.00795685\n",
      " -0.6065951   0.68344635  0.13672569 -0.65008813  0.0973195   0.68627191\n",
      " -0.27609709 -0.06840514 -0.47877073  0.67392933  0.57564646  0.6931138\n",
      "  0.20337099  0.67060256  0.73221499  0.66021156  0.48189974 -0.10990331\n",
      "  0.22841033 -0.6689167 ]\n",
      "{'name': 'dense_3', 'trainable': True, 'units': 10, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(50, 10)\n",
      "Second:\n",
      "[ 0.03334926 -0.79141098 -0.78335601  0.75025761 -0.77814603 -0.39848489\n",
      " -0.50240034  0.74340993  0.7936421  -0.77566707]\n",
      "{'name': 'dense_4', 'trainable': True, 'units': 1, 'activation': 'linear', 'use_bias': True, 'kernel_initializer': {'class_name': 'VarianceScaling', 'config': {'scale': 1.0, 'mode': 'fan_avg', 'distribution': 'uniform', 'seed': None}}, 'bias_initializer': {'class_name': 'Zeros', 'config': {}}, 'kernel_regularizer': None, 'bias_regularizer': None, 'activity_regularizer': None, 'kernel_constraint': None, 'bias_constraint': None}\n",
      "First:\n",
      "(10, 1)\n",
      "Second:\n",
      "[ 0.82336074]\n"
     ]
    }
   ],
   "source": [
    "for layer in model.layers:\n",
    "    g=layer.get_config()\n",
    "    h=layer.get_weights()\n",
    "    print (g)\n",
    "    if len(h) > 0:\n",
    "        print(\"First:\")\n",
    "        print(h[0].shape)\n",
    "        print(\"Second:\")\n",
    "        print(h[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.1/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'input_img' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-c782697c1e8a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# compute the gradient of the input picture wrt this loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mgrads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;31m# normalization trick: we normalize the gradient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'input_img' is not defined"
     ]
    }
   ],
   "source": [
    "from keras import applications\n",
    "\n",
    "# build the VGG16 network\n",
    "model = applications.VGG16(include_top=False,\n",
    "                           weights='imagenet')\n",
    "\n",
    "# get the symbolic outputs of each \"key\" layer (we gave them unique names).\n",
    "layer_dict = dict([(layer.name, layer) for layer in model.layers])\n",
    "\n",
    "from keras import backend as K\n",
    "\n",
    "layer_name = 'block5_conv3'\n",
    "filter_index = 0  # can be any integer from 0 to 511, as there are 512 filters in that layer\n",
    "\n",
    "# build a loss function that maximizes the activation\n",
    "# of the nth filter of the layer considered\n",
    "layer_output = layer_dict[layer_name].output\n",
    "loss = K.mean(layer_output[:, :, :, filter_index])\n",
    "\n",
    "# compute the gradient of the input picture wrt this loss\n",
    "grads = K.gradients(loss, input_img)[0]\n",
    "\n",
    "# normalization trick: we normalize the gradient\n",
    "grads /= (K.sqrt(K.mean(K.square(grads))) + 1e-5)\n",
    "\n",
    "# this function returns the loss and grads given the input picture\n",
    "iterate = K.function([input_img], [loss, grads])\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# we start from a gray image with some noise\n",
    "input_img_data = np.random.random((1, 3, img_width, img_height)) * 20 + 128.\n",
    "# run gradient ascent for 20 steps\n",
    "for i in range(20):\n",
    "    loss_value, grads_value = iterate([input_img_data])\n",
    "    input_img_data += grads_value * step\n",
    "    \n",
    "from scipy.misc import imsave\n",
    "\n",
    "# util function to convert a tensor into a valid image\n",
    "def deprocess_image(x):\n",
    "    # normalize tensor: center on 0., ensure std is 0.1\n",
    "    x -= x.mean()\n",
    "    x /= (x.std() + 1e-5)\n",
    "    x *= 0.1\n",
    "\n",
    "    # clip to [0, 1]\n",
    "    x += 0.5\n",
    "    x = np.clip(x, 0, 1)\n",
    "\n",
    "    # convert to RGB array\n",
    "    x *= 255\n",
    "    x = x.transpose((1, 2, 0))\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x\n",
    "\n",
    "img = input_img_data[0]\n",
    "img = deprocess_image(img)\n",
    "imsave('%s_filter_%d.png' % (layer_name, filter_index), img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'urllib2'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-238ba110c54f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0murllib2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'pylab inline'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'urllib2'"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from urllib2 import urlopen\n",
    "import numpy as np\n",
    "%pylab inline\n",
    "\n",
    "page = urlopen(\"http://datasets.flowingdata.com/ppg2008.csv\")\n",
    "nba = pd.read_csv(page, index_col=0)\n",
    "\n",
    "# Normalize data columns\n",
    "nba_norm = (nba - nba.mean()) / (nba.max() - nba.min())\n",
    "\n",
    "# Sort data according to Points, lowest to highest\n",
    "# This was just a design choice made by Yau\n",
    "# inplace=False (default) ->thanks SO user d1337\n",
    "nba_sort = nba_norm.sort('PTS', ascending=True)\n",
    "\n",
    "nba_sort['PTS'].head(10)\n",
    "\n",
    "# Plot it out\n",
    "fig, ax = plt.subplots()\n",
    "heatmap = ax.pcolor(nba_sort, cmap=plt.cm.Blues, alpha=0.8)\n",
    "\n",
    "# Format\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(8, 11)\n",
    "\n",
    "# turn off the frame\n",
    "ax.set_frame_on(False)\n",
    "\n",
    "# put the major ticks at the middle of each cell\n",
    "ax.set_yticks(np.arange(nba_sort.shape[0]) + 0.5, minor=False)\n",
    "ax.set_xticks(np.arange(nba_sort.shape[1]) + 0.5, minor=False)\n",
    "\n",
    "# want a more natural, table-like display\n",
    "ax.invert_yaxis()\n",
    "ax.xaxis.tick_top()\n",
    "\n",
    "# Set the labels\n",
    "\n",
    "# label source:https://en.wikipedia.org/wiki/Basketball_statistics\n",
    "labels = [\n",
    "    'Games', 'Minutes', 'Points', 'Field goals made', 'Field goal attempts', 'Field goal percentage', 'Free throws made', 'Free throws attempts', 'Free throws percentage',\n",
    "    'Three-pointers made', 'Three-point attempt', 'Three-point percentage', 'Offensive rebounds', 'Defensive rebounds', 'Total rebounds', 'Assists', 'Steals', 'Blocks', 'Turnover', 'Personal foul']\n",
    "\n",
    "# note I could have used nba_sort.columns but made \"labels\" instead\n",
    "ax.set_xticklabels(labels, minor=False)\n",
    "ax.set_yticklabels(nba_sort.index, minor=False)\n",
    "\n",
    "# rotate the\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "ax.grid(False)\n",
    "\n",
    "# Turn off all the ticks\n",
    "ax = plt.gca()\n",
    "\n",
    "for t in ax.xaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False\n",
    "for t in ax.yaxis.get_major_ticks():\n",
    "    t.tick1On = False\n",
    "    t.tick2On = False"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
